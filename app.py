# app.py ã‚’ EDAãƒ¢ãƒ¼ãƒ‰ã«æ›´æ–°
import sys, json
from src.core.types import Step, RunLog, ActionType
from typing import cast
from src.llm.client import LLMClient
from src.planning.loop import execute_plan
from src.agents.eda_agent import initial_eda_plan
from src.planning.loop import next_eda_plan
from src.reports.report import render_eda
from src.utils.integrated_progress import get_global_progress_system, reset_global_progress_system
try:
    import streamlit as st  # type: ignore[reportMissingImports]
except Exception:
    st = None  # type: ignore[assignment]
import os, json, time
from src.agents.model_agent import infer_task_and_target, train_candidates
from dotenv import load_dotenv


load_dotenv()

sample = False

if st:
        st.set_page_config(page_title="AI EDA Agent", layout="wide")
        st.title("Autonomous EDA & Modeling Agent")
        with st.sidebar:
            st.header("è¨­å®š")
            up = st.file_uploader("CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])
            sample = st.checkbox("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™", value=False)
            run = st.button("å®Ÿè¡Œ")
            # Insights ãƒ©ã‚¦ãƒ³ãƒ‰æ•°ï¼ˆUIã§åˆ¶å¾¡ï¼‰
            try:
                _def_rounds = int(os.getenv("INSIGHT_ROUNDS", "3"))
            except Exception:
                _def_rounds = 3
            _opts = [1, 2, 3, 4, 5]
            _idx = _opts.index(_def_rounds) if _def_rounds in _opts else _opts.index(3)
            insight_rounds = st.selectbox(
                "Insights ãƒ©ã‚¦ãƒ³ãƒ‰æ•°",
                _opts,
                index=_idx,
                help="LLMå†…çœã®åå¾©å›æ•°ï¼ˆå¤šã„ã»ã©é«˜å“è³ªã ãŒé…ããªã‚Šã¾ã™ï¼‰",
            )
            # LLM ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®å¯è¦–åŒ–
            try:
                _prov = os.getenv("LLM_PROVIDER", "anthropic")
                _model = os.getenv("LLM_MODEL", "claude-sonnet-4-20250514")
                st.caption(f"LLM provider: {_prov}")
                st.caption(f"LLM model: {_model}")
                _has = False
                try:
                    _tmp = LLMClient()
                    _has = _tmp.is_ready(deep=False)
                    _deep_ok = False
                    if _has:
                        # Deep check trigger
                        if st.button("LLM æ¥ç¶šç¢ºèª", use_container_width=True):
                            _deep_ok = _tmp.is_ready(deep=True)
                    if _has:
                        st.success("LLM ready")
                        if _deep_ok:
                            st.caption("Deep check: OK")
                    else:
                        st.warning("LLM not ready (check API key and provider)")
                except Exception:
                    _has = False
                    st.warning("LLM not ready (init error)")
            except Exception:
                pass
else:
    up = None
    run = False
if st and run and (up or sample):
    csv_path = "data/upload.csv"
    if up:
        with open(csv_path, "wb") as f: f.write(up.read())
    else:
        import pandas as pd
        os.makedirs("data", exist_ok=True)
        import numpy as np
        n = 300
        df = pd.DataFrame({
            "feature_num": np.random.randn(n)*2+3,
            "feature_cat": np.random.choice(["A","B","C"], size=n, p=[0.5,0.3,0.2]),
            "target": np.random.choice([0,1], size=n)
        })
        df.to_csv(csv_path, index=False)
    st.write("å®Ÿè¡Œé–‹å§‹â€¦")
    llm = LLMClient()
    log = RunLog(meta={"input_csv": csv_path})
    
    # çµ±åˆé€²æ—ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    reset_global_progress_system()  # å‰å›ã®çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
    progress_system = get_global_progress_system()

    # çµ±åˆé€²æ—ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’Streamlitã«è¿½åŠ 
    progress_containers = progress_system.get_streamlit_containers()
    
    eda_tab, figs_tab, desc_tab, insights_tab, artifacts_tab, progress_tab = st.tabs(["Overview","Figures","Describe","Insights","Artifacts","é€²æ—"])

    with st.status("EDAä¸­...", expanded=True) as status:
        reflect_rounds_ui = 2
        phase_count = 1 + reflect_rounds_ui
        phase_idx = 0
        
        # EDAåˆæœŸãƒ—ãƒ©ãƒ³
        progress_system.start_phase("EDAåˆæœŸåˆ†æ", message="ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çš„ãªæ¢ç´¢ã‚’é–‹å§‹ã—ã¾ã™")
        steps = initial_eda_plan(llm)
        
        prog = st.progress(0.0)
        logbox = st.empty()
        stagebox = st.empty()
        report_box = st.empty()
        total = max(1, len(steps))
        
        def _on(idx, step, obs):
            # å„ãƒ•ã‚§ãƒ¼ã‚ºã‚’åŒã˜é‡ã¿ã§é€²æ—åŒ–
            local = (idx + 1) / max(1, total)
            overall = (phase_idx + local) / phase_count
            status.update(label=f"EDAä¸­... {int(overall*100)}% (Phase {phase_idx+1}/{phase_count})")
            prog.progress(min(1.0, overall))
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸è¡¨ç¤ºï¼ˆaction ã¨ã‚³ãƒ¼ãƒ‰/ãƒãƒ¼ãƒˆå…ˆé ­ï¼‰
            preview = (step.note or (step.code or "").strip().splitlines()[0:1])
            if isinstance(preview, list):
                preview = preview[0] if preview else ""
            stagebox.write({
                "phase": f"{phase_idx+1}/{phase_count}",
                "step": f"{idx+1}/{total}",
                "action": step.action,
                "preview": (preview or "")[:120]
            })
            logbox.write({
                "ok": obs.success,
                "stdout": obs.stdout[-400:],
                "stderr": obs.stderr[-400:]
            })
            
            # çµ±åˆé€²æ—ã‚·ã‚¹ãƒ†ãƒ ã«æƒ…å ±ã‚’é€ä¿¡
            step_name = f"{step.action}: {(preview or '')[:50]}"
            progress_system.update_step(step_name, f"ã‚¹ãƒ†ãƒƒãƒ— {idx+1}/{total}")
        
        log = execute_plan(steps, csv_path, log, on_step=_on, 
                          progress_manager=progress_system.progress_manager, 
                          phase_name="EDAåˆæœŸåˆ†æ")
        
        phase_idx += 1
        
        # åçœãƒ»æ”¹å–„ãƒ•ã‚§ãƒ¼ã‚º
        for i in range(reflect_rounds_ui):
            progress_system.start_phase(f"EDAæ”¹å–„ ãƒ©ã‚¦ãƒ³ãƒ‰{i+1}", message=f"åˆ†æçµæœã‚’æ”¹å–„ã—ã¾ã™ï¼ˆ{i+1}/{reflect_rounds_ui}ï¼‰")
            steps = next_eda_plan(llm, log)
            total = max(1, len(steps))
            log = execute_plan(steps, csv_path, log, on_step=_on,
                              progress_manager=progress_system.progress_manager,
                              phase_name=f"EDAæ”¹å–„ ãƒ©ã‚¦ãƒ³ãƒ‰{i+1}")
            phase_idx += 1
        
        progress_system.complete_phase("EDAåˆ†æå®Œäº†")
        md = render_eda(csv_path)
        with eda_tab:
            st.subheader("ãƒ¬ãƒãƒ¼ãƒˆ")
            report_box.markdown(open("data/artifacts/eda_report.md","r",encoding="utf-8").read(), unsafe_allow_html=True)
            # Inline figures fallback (Markdown image links may not render reliably)
            from pathlib import Path as _P
            _art = _P("data/artifacts")
            _imgs = sorted(_art.glob("cell_hist_*.png"))
            if _imgs:
                st.subheader("Figures (inline)")
                _cols = st.columns(3)
                for _i, _p in enumerate(_imgs):
                    with _cols[_i % 3]:
                        st.image(str(_p), caption=_p.name)
            _mimgs = sorted(_art.glob("model_*.png"))
            if _mimgs:
                st.subheader("Modeling Figures (inline)")
                _cols2 = st.columns(3)
                for _i, _p in enumerate(_mimgs):
                    with _cols2[_i % 3]:
                        st.image(str(_p), caption=_p.name)

    with st.status("ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ä¸­...", expanded=True) as mstatus:
        import pandas as pd  # type: ignore[reportMissingImports]
        try:
            df = pd.read_csv(csv_path)
            st.write("ãƒ‡ãƒ¼ã‚¿èª­è¾¼å®Œäº†", df.shape)
            task, ycol = infer_task_and_target(df)
            st.write("æ¨å®šã‚¿ã‚¹ã‚¯", task, "/ ç›®çš„å¤‰æ•°", ycol)
            mprog = st.progress(0.0)
            mstage = st.empty()
            def _mcb(stage: str, frac: float) -> None:
                mstatus.update(label=f"ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ä¸­... {int(max(0.0,min(1.0,frac))*100)}%")
                mprog.progress(min(1.0, max(0.0, frac)))
                mstage.write({"stage": stage, "progress": f"{frac*100:.1f}%"})
            res = train_candidates(df, task, ycol, progress=_mcb)
            with eda_tab:
                st.subheader("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
                st.json(res)
            open("data/artifacts/model_scores.json","w").write(json.dumps(res,ensure_ascii=False,indent=2))
            # è¿½åŠ ã®åˆ†æ
            try:
                import numpy as np
                from sklearn.model_selection import train_test_split
                from sklearn.linear_model import LogisticRegression
                from src.agents.error_analysis import (
                    ensure_dir, save_confusion_matrix, save_roc_pr_curves, save_permutation_importance_png, save_slice_metrics_csv,
                    save_threshold_curve, save_partial_dependence_png, save_partial_correlation_csv, save_missing_impact_csv
                )
                import warnings as _warnings
                _warnings.filterwarnings("ignore", module="sklearn.utils.extmath")
                ensure_dir("data/artifacts")
                mstatus.update(label="è¿½åŠ åˆ†æä¸­...")
                subprog = st.progress(0.0)
                substage = st.empty()
                # Build fine-grained stage plan dynamically
                y = df[ycol]
                X = pd.get_dummies(df.drop(columns=[ycol]), drop_first=True).fillna(0.0)
                y_codes = y.astype('category').cat.codes
                mask = (y_codes >= 0)
                X = X.loc[mask]
                y_codes = y_codes.loc[mask]
                strat = y_codes if len(np.unique(y_codes)) > 1 else None
                top_num = list(X.columns[:3])
                binary = len(np.unique(y_codes)) == 2
                stages: list[str] = [
                    "prepare data",
                    "train/test split",
                    "fit(LogisticRegression)",
                    "predict labels",
                ]
                if binary:
                    stages += [
                        "predict probabilities",
                        "save ROC",
                        "save PR",
                        "save threshold curve",
                    ]
                stages += [
                    "save confusion matrix",
                    "permutation importance (compute+save)",
                    "slice metrics (save)",
                ]
                for f in top_num:
                    stages.append(f"save PDP: {f}")
                stages += [
                    "save partial correlation",
                    "save missingness impact",
                ]
                total_steps = len(stages)
                cur = [0]
                def _sub(stage: str):
                    subprog.progress(min(1.0, (cur[0]+1)/total_steps))
                    substage.write({"stage": stage, "step": f"{cur[0]+1}/{total_steps}"})
                    cur[0] += 1
                # Execute with detailed updates
                _sub("prepare data")
                # data prepared above
                _sub("train/test split")
                Xtr, Xte, ytr, yte = train_test_split(X, y_codes, test_size=0.3, random_state=42, stratify=strat)
                clf = LogisticRegression(max_iter=2000)
                _sub("fit(LogisticRegression)")
                clf.fit(Xtr, ytr)
                _sub("predict labels")
                ypred = clf.predict(Xte).astype(int)
                if binary:
                    _sub("predict probabilities")
                    yscore = clf.predict_proba(Xte)[:,1]
                    if np.isfinite(yscore).all():
                        _sub("save ROC")
                        save_roc_pr_curves(yte, yscore, 'data/artifacts/model_roc.png', 'data/artifacts/model_pr.png')
                        _sub("save PR")
                        # ROC/PRã¯åŒä¸€å‘¼å‡ºã§ä¸¡æ–¹ä¿å­˜ã™ã‚‹ãŸã‚ã€PRç”¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚‚è¡¨ç¤º
                        _ = None
                        _sub("save threshold curve")
                        save_threshold_curve(yte, yscore, 'data/artifacts/model_threshold.png')
                _sub("save confusion matrix")
                save_confusion_matrix(list(map(int, yte.tolist())), list(map(int, ypred.tolist())), 'data/artifacts/model_confusion.png', labels=list(df[ycol].astype('category').cat.categories))
                _sub("permutation importance (compute+save)")
                save_permutation_importance_png(clf, Xte, yte, 'data/artifacts/model_permutation_importance.png')
                _sub("slice metrics (save)")
                save_slice_metrics_csv(df.loc[Xte.index], yte, ypred, ycol, 'data/artifacts/model_slice_metrics.csv')
                # PDP per feature
                for f in top_num:
                    _sub(f"save PDP: {f}")
                    save_partial_dependence_png(clf, Xte, [f], 'data/artifacts')
                _sub("save partial correlation")
                save_partial_correlation_csv(df.select_dtypes(include='number'), 'data/artifacts/model_partial_corr.csv')
                _sub("save missingness impact")
                save_missing_impact_csv(df, ycol, 'data/artifacts/model_missing_impact.csv')
                # Insights ç”Ÿæˆã¯å¾Œæ®µã§å¿…ãšå®Ÿæ–½ï¼ˆè¿½åŠ åˆ†æã®å¤±æ•—ã«å½±éŸ¿ã•ã›ãªã„ï¼‰
            except Exception as ee:
                st.warning(f"è¿½åŠ åˆ†æã§è­¦å‘Š: {ee}")
            mstatus.update(label="ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å®Œäº†", state="complete")
            # ãƒ¬ãƒãƒ¼ãƒˆã‚’å†ãƒ¬ãƒ³ãƒ€ï¼ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°å›³ã‚’å«ã‚ã‚‹ãŸã‚ï¼‰
            md = render_eda(csv_path)
            with eda_tab:
                report_box.markdown(open("data/artifacts/eda_report.md","r",encoding="utf-8").read(), unsafe_allow_html=True)
            # ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å›³ã®ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æç”»ï¼ˆãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå¾Œã«æ”¹ã‚ã¦è¡¨ç¤ºï¼‰
            from pathlib import Path as _P2
            _art2 = _P2('data/artifacts')
            _mimgs2 = sorted(_art2.glob('model_*.png'))
            if _mimgs2:
                with eda_tab:
                    st.subheader("Modeling Figures (inline)")
                    _colsM = st.columns(3)
                    for _i, _p in enumerate(_mimgs2):
                        with _colsM[_i % 3]:
                            st.image(str(_p), caption=_p.name)
            # ---- LLM Insightsï¼ˆè¿½åŠ åˆ†æã®æˆå¦ã«é–¢ã‚ã‚‰ãšå®Ÿè¡Œï¼‰ ----
            try:
                from pathlib import Path as _P
                art = _P('data/artifacts'); art.mkdir(parents=True, exist_ok=True)
                ctx_parts = []
                ctx_parts.append('Model scores: ' + json.dumps(res, ensure_ascii=False))
                for _fn in ['model_slice_metrics.csv','model_missing_impact.csv','model_partial_corr.csv']:
                    _p = art/_fn
                    if _p.exists():
                        try:
                            import pandas as _pd
                            _dfh = _pd.read_csv(_p).head(20).to_string(index=False)
                            ctx_parts.append(f'{_fn} (head):\n{_dfh}')
                        except Exception:
                            pass
                _ins = ""
                has_llm_ui = (llm is not None) and (getattr(llm, '_client', None) is not None)
                # Prepare Overview tab placeholders so users see insights without switching tabs
                with eda_tab:
                    st.subheader('Insights (LLM)')
                    _draft_box_ov = st.empty()
                    _ov_prog = st.progress(0.0)
                    _ov_log = st.empty()
                    _ov_eta = st.empty()
                with insights_tab:
                    st.subheader('Insights (LLM)')
                    # Show intermediate drafts while generating (Insights tab)
                    _draft_box = st.empty()
                    if has_llm_ui:
                        with st.status("Insights ç”Ÿæˆä¸­...", expanded=True):
                            iprog = st.progress(0.0)
                            ilog = st.empty()
                            _eta_box = st.empty()
                            _round_start: dict[int, float] = {}
                            _round_times: dict[int, float] = {}
                            stream_accum = [""]
                            def _ipcb(round_idx: int, total: int) -> None:
                                # Called at the start of each round
                                frac = min(1.0, max(0.0, (round_idx-1)/float(total)))
                                iprog.progress(frac)
                                # Mirror to Overview tab
                                try:
                                    _ov_prog.progress(frac)
                                except Exception:
                                    pass
                                _round_start[round_idx] = time.time()
                                ilog.write({
                                    "round": f"{round_idx}/{total}",
                                    "status": "calling LLM",
                                    "started_at": time.strftime('%H:%M:%S')
                                })
                                try:
                                    _ov_log.write({
                                        "round": f"{round_idx}/{total}",
                                        "status": "calling LLM",
                                        "started_at": time.strftime('%H:%M:%S')
                                    })
                                except Exception:
                                    pass
                                # ETA based on previous rounds (if any)
                                if _round_times:
                                    avg = sum(_round_times.values())/len(_round_times)
                                    rem = max(0, total - (round_idx-1))
                                    _eta_box.info(f"ETA ç´„ {int(avg*rem)} ç§’ï¼ˆå¹³å‡ {avg:.1f}s/ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰")
                                    try:
                                        _ov_eta.info(f"ETA ç´„ {int(avg*rem)} ç§’ï¼ˆå¹³å‡ {avg:.1f}s/ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰")
                                    except Exception:
                                        pass
                                else:
                                    _eta_box.caption("ETA è¨ˆæ¸¬ä¸­â€¦ï¼ˆæœ€åˆã®ãƒ©ã‚¦ãƒ³ãƒ‰å®Œäº†å¾Œã«æ¨å®šï¼‰")
                                    try:
                                        _ov_eta.caption("ETA è¨ˆæ¸¬ä¸­â€¦ï¼ˆæœ€åˆã®ãƒ©ã‚¦ãƒ³ãƒ‰å®Œäº†å¾Œã«æ¨å®šï¼‰")
                                    except Exception:
                                        pass
                            def _idcb(draft_text: str, round_idx: int, total: int) -> None:
                                # Stream the evolving draft so users can see progress
                                _draft_box.markdown(draft_text or '')
                                try:
                                    _draft_box_ov.markdown(draft_text or '')
                                except Exception:
                                    pass
                                # Round finished timing and ETA update
                                stt = _round_start.get(round_idx, time.time())
                                dur = max(0.0, time.time() - stt)
                                _round_times[round_idx] = dur
                                ilog.write({
                                    "round": f"{round_idx}/{total}",
                                    "status": "round finished",
                                    "duration_sec": f"{dur:.1f}",
                                })
                                try:
                                    _ov_log.write({
                                        "round": f"{round_idx}/{total}",
                                        "status": "round finished",
                                        "duration_sec": f"{dur:.1f}",
                                    })
                                except Exception:
                                    pass
                                avg = sum(_round_times.values())/len(_round_times)
                                rem = max(0, total - round_idx)
                                _eta_box.info(f"ETA ç´„ {int(avg*rem)} ç§’ï¼ˆå¹³å‡ {avg:.1f}s/ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰")
                                iprog.progress(min(1.0, round_idx/float(total)))
                                try:
                                    _ov_eta.info(f"ETA ç´„ {int(avg*rem)} ç§’ï¼ˆå¹³å‡ {avg:.1f}s/ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰")
                                    _ov_prog.progress(min(1.0, round_idx/float(total)))
                                except Exception:
                                    pass
                                # Persist draft after each round as well
                                try:
                                    (art/f'insights_round_{round_idx}.md').write_text(draft_text or '', encoding='utf-8')
                                    (art/'insights.md').write_text(draft_text or '', encoding='utf-8')
                                except Exception:
                                    pass
                            def _istream(delta_text: str, round_idx: int, total: int) -> None:
                                # Token/fragment-level streaming update (more granular than on_draft)
                                stream_accum[0] += (delta_text or '')
                                _draft_box.markdown(stream_accum[0])
                                try:
                                    _draft_box_ov.markdown(stream_accum[0])
                                except Exception:
                                    pass
                            from src.agents.explain import generate_insights
                            _rounds = insight_rounds if 'insight_rounds' in locals() and insight_rounds is not None else int(os.getenv("INSIGHT_ROUNDS", "3"))
                            _ins = generate_insights(llm, "\n\n".join(ctx_parts), rounds=_rounds, progress=_ipcb, on_draft=_idcb, on_stream=_istream)
                            (art/'insights.md').write_text(_ins or '', encoding='utf-8')
                            ilog.write({"done": True})
                    else:
                        # LLMæœªè¨­å®š/ç„¡åŠ¹æ™‚ã¯æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤ºã€ãªã‘ã‚Œã°æ¡ˆå†…ã‚’è¡¨ç¤º
                        _p_ins = art/'insights.md'
                        if _p_ins.exists():
                            try:
                                _ins = _p_ins.read_text(encoding='utf-8')
                            except Exception:
                                _ins = ''
                        if not _ins.strip():
                            st.info('LLM ãŒç„¡åŠ¹ã‹æœªè¨­å®šã®ãŸã‚ Insights ã¯æœªç”Ÿæˆã§ã™ã€‚OPENAI_API_KEY/ANTHROPIC_API_KEY ã¨ LLM_PROVIDER/LLM_MODEL ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚')
                    if _ins.strip():
                        _draft_box.markdown(_ins)
                        st.download_button('Insights Markdown', data=_ins.encode('utf-8'), file_name='insights.md')
                # Also show final insights and download on Overview
                if _ins.strip():
                    with eda_tab:
                        _draft_box_ov.markdown(_ins)
                        st.download_button('Insights Markdown', data=_ins.encode('utf-8'), file_name='insights.md', key='dl_insights_overview')

                # Reflect insights into follow-up improvements and re-train
                try:
                    if has_llm_ui and _ins.strip():
                        from src.agents.model_agent import reflect_and_improve
                        from src.runners.code_runner import run_python as _run_py
                        # Prepare Overview placeholders
                        with eda_tab:
                            st.subheader("ç¤ºå”†ã®åæ˜ ã¨å†å­¦ç¿’")
                            rprog_ov = st.progress(0.0)
                            rlog_ov = st.empty()
                        with insights_tab:
                            st.subheader("ç¤ºå”†ã®åæ˜ ã¨å†å­¦ç¿’")
                            rprog = st.progress(0.0)
                            rlog = st.empty()
                            steps2 = reflect_and_improve(llm, json.dumps(res, ensure_ascii=False), extra_context=_ins)
                            if steps2:
                                for si, _s in enumerate(steps2):
                                    if _s.get('action') == 'python':
                                        msg = {"apply_step": si+1, "total": len(steps2)}
                                        rlog.write(msg)
                                        try:
                                            rlog_ov.write(msg)
                                        except Exception:
                                            pass
                                        _run_py(_s.get('code', ''), input_csv=csv_path)
                                        frac = (si+1)/len(steps2)
                                        rprog.progress(frac)
                                        try:
                                            rprog_ov.progress(frac)
                                        except Exception:
                                            pass
                                # Re-train after applying suggestions
                                df2 = pd.read_csv(csv_path)
                                res2 = train_candidates(df2, task, ycol)
                                open("data/artifacts/model_scores.json","w").write(json.dumps(res2,ensure_ascii=False,indent=2))
                                with eda_tab:
                                    st.subheader("ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ï¼ˆæ”¹å–„å¾Œï¼‰")
                                    st.json(res2)
                                # Re-render report and inline figures
                                md = render_eda(csv_path)
                                report_box.markdown(open("data/artifacts/eda_report.md","r",encoding="utf-8").read(), unsafe_allow_html=True)
                                from pathlib import Path as _P3
                                _art3 = _P3('data/artifacts')
                                _mimgs3 = sorted(_art3.glob('model_*.png'))
                                if _mimgs3:
                                    with eda_tab:
                                        st.subheader("Modeling Figures (inline, æ”¹å–„å¾Œ)")
                                        _colsM2 = st.columns(3)
                                        for _i, _p in enumerate(_mimgs3):
                                            with _colsM2[_i % 3]:
                                                st.image(str(_p), caption=_p.name)
                            else:
                                rlog.write({"info": "æ”¹å–„æ‰‹é †ã¯ç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"})
                except Exception as _re:
                    with insights_tab:
                        st.warning(f"åæ˜ å†å®Ÿè¡Œã§è­¦å‘Š: {_re}")
            except Exception as _ie:
                with insights_tab:
                    st.warning(f"Insightsç”Ÿæˆã§è­¦å‘Š: {_ie}")
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã§ã‚¨ãƒ©ãƒ¼: {e}")

    from pathlib import Path
    art = Path("data/artifacts")
    with figs_tab:
        st.subheader("å›³è¡¨")
        imgs = sorted(art.glob("cell_hist_*.png"))
        if imgs:
            cols = st.columns(3)
            for i, p in enumerate(imgs):
                with cols[i%3]:
                    st.image(str(p), caption=p.name)
        else:
            st.info("å›³ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“")
    with desc_tab:
        st.subheader("describe")
        desc = art / "cell_desc.csv"
        if desc.exists():
            import pandas as pd
            st.dataframe(pd.read_csv(desc))
        else:
            st.info("describe ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“")
    with artifacts_tab:
        st.subheader("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        if (art/"eda_report.md").exists():
            st.download_button("EDA Markdown", data=open(art/"eda_report.md","rb").read(), file_name="eda_report.md")
        if (art/"model_scores.json").exists():
            st.download_button("Model Scores JSON", data=open(art/"model_scores.json","rb").read(), file_name="model_scores.json")
    
    # é€²æ—ã‚¿ãƒ–ã®å†…å®¹
    with progress_tab:
        st.subheader("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        
        # é€²æ—æ¦‚è¦
        overall_status = progress_system.get_overall_status()
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç¾åœ¨ã®ãƒ•ã‚§ãƒ¼ã‚º", overall_status["current_phase"])
        with col2:
            progress_percent = int(overall_status["progress"]["current_state"]["progress"] * 100)
            st.metric("é€²æ—ç‡", f"{progress_percent}%")
        with col3:
            st.metric("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", overall_status["status"])
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†
        st.subheader("ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†")
        
        col_cp1, col_cp2 = st.columns(2)
        with col_cp1:
            if st.button("æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆ"):
                checkpoint_id = progress_system.save_checkpoint("æ‰‹å‹•ä½œæˆ")
                if checkpoint_id:
                    st.success(f"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆå®Œäº†: {checkpoint_id}")
                else:
                    st.error("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        with col_cp2:
            checkpoints = progress_system.list_checkpoints()
            if checkpoints:
                checkpoint_names = [f"{cp.checkpoint_id} ({cp.description})" for cp in checkpoints]
                selected_cp = st.selectbox("å¾©å…ƒã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ", ["é¸æŠã—ã¦ãã ã•ã„"] + checkpoint_names)
                
                if selected_cp != "é¸æŠã—ã¦ãã ã•ã„" and selected_cp is not None:
                    checkpoint_id = selected_cp.split(" (")[0]
                    if st.button("å¾©å…ƒå®Ÿè¡Œ"):
                        if progress_system.restore_checkpoint(checkpoint_id):
                            st.success("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒå®Œäº†")
                            st.experimental_rerun()
                        else:
                            st.error("ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # è©³ç´°é€²æ—æƒ…å ±
        st.subheader("ğŸ“Š è©³ç´°é€²æ—æƒ…å ±")
        progress_details = overall_status["progress"]
        st.json(progress_details)
        
        # ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
        st.subheader("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
        with st.expander("é€²æ—ã‚·ã‚¹ãƒ†ãƒ è¨­å®š"):
            st.write("**é€šçŸ¥è¨­å®š**")
            st.code(f"""
NOTIFICATION_EMAIL_ENABLED={os.getenv('NOTIFICATION_EMAIL_ENABLED', 'false')}
NOTIFICATION_WEBHOOK_ENABLED={os.getenv('NOTIFICATION_WEBHOOK_ENABLED', 'false')}
NOTIFICATION_DESKTOP_ENABLED={os.getenv('NOTIFICATION_DESKTOP_ENABLED', 'false')}
            """)
            
            st.write("**ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š**")
            if "checkpoint_info" in overall_status:
                cp_info = overall_status["checkpoint_info"]
                st.write(f"ä¿å­˜æ¸ˆã¿ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {cp_info['checkpoint_count']}å€‹")
                st.write(f"ç·ã‚µã‚¤ã‚º: {cp_info['total_size_mb']:.1f}MB")
                st.write(f"è‡ªå‹•ä¿å­˜: {'æœ‰åŠ¹' if cp_info['auto_save_enabled'] else 'ç„¡åŠ¹'}")
                st.write(f"ä¿å­˜é–“éš”: {cp_info['auto_save_interval']/60:.1f}åˆ†")
        
        # ãƒ­ã‚°è¡¨ç¤º
        st.subheader("ğŸ“ é€²æ—ãƒ­ã‚°")
        log_file = Path("data/artifacts/progress.log")
        if log_file.exists():
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    log_lines = f.readlines()[-20:]  # æœ€æ–°20è¡Œ
                
                log_text = "".join(log_lines)
                st.code(log_text, language="text")
            except Exception as e:
                st.error(f"ãƒ­ã‚°èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.info("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã ä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
if __name__ == "__main__" and os.getenv("CLI","0") == "1":
    csv = sys.argv[1] if len(sys.argv) > 1 else "data/sample.csv"
    log = RunLog(meta={"input_csv": csv})
    
    # CLIç”¨ã®çµ±åˆé€²æ—ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆStreamlitç„¡åŠ¹ã€ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›æœ‰åŠ¹ï¼‰
    from src.utils.integrated_progress import create_integrated_progress_system
    cli_progress = create_integrated_progress_system(
        enable_dashboard=False,  # CLI ã§ã¯Streamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç„¡åŠ¹
        enable_notifications=True,
        enable_checkpoints=True,
        enable_console_output=True
    )
    
    try:
        llm = LLMClient()
    except Exception:
        llm = None  # type: ignore
    # CLI ã§ã¯æ—¢å®šã§ LLM ã‚’ä½¿ã‚ãªã„ï¼ˆãƒãƒƒãƒˆä¾å­˜/é…å»¶å›é¿ï¼‰ã€‚æœ‰åŠ¹åŒ–ã™ã‚‹ã«ã¯ USE_LLM=1 ã‚’è¨­å®šã€‚
    use_llm_cli = os.getenv("USE_LLM", "0") == "1"
    has_llm = bool(llm) and llm.is_ready(deep=False) and use_llm_cli

    # 1) åˆæœŸãƒ—ãƒ©ãƒ³å®Ÿè¡Œï¼ˆLLMãªã—ãªã‚‰few-shotã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    cli_progress.start_phase("EDAåˆæœŸåˆ†æ", message="CLI ãƒ¢ãƒ¼ãƒ‰ã§EDAåˆ†æã‚’é–‹å§‹")
    
    if has_llm:
        assert llm is not None
        steps = initial_eda_plan(llm)
    else:
        from src.agents.eda_agent import EDA_FEWSHOT
        steps = [
            Step(
                action=cast(ActionType, s.get("action")),
                code=s.get("code"),
                note=s.get("note")
            ) for s in EDA_FEWSHOT
        ]
    
    # CLI é€²æ—è¡¨ç¤ºï¼ˆç°¡æ˜“ + çµ±åˆé€²æ—ã‚·ã‚¹ãƒ†ãƒ ï¼‰
    phase_count = 1 + (2 if has_llm else 0)
    phase_idx = 0
    total = max(1, len(steps))
    
    def _on_cli(idx, step, obs):
        local = (idx + 1) / max(1, total)
        overall = (phase_idx + local) / phase_count
        preview = step.note or (step.code or "").strip().splitlines()[0:1]
        if isinstance(preview, list):
            preview = preview[0] if preview else ""
        
        # å¾“æ¥ã®JSONå‡ºåŠ›
        print(json.dumps({
            "event": "eda_step",
            "phase": f"{phase_idx+1}/{phase_count}",
            "step": f"{idx+1}/{total}",
            "action": step.action,
            "ok": obs.success,
            "overall": round(overall, 3),
            "preview": (preview or "")[:120]
        }, ensure_ascii=False))
        
        # çµ±åˆé€²æ—ã‚·ã‚¹ãƒ†ãƒ æ›´æ–°
        step_name = f"{step.action}: {(preview or '')[:50]}"
        cli_progress.update_step(step_name, f"ã‚¹ãƒ†ãƒƒãƒ— {idx+1}/{total}")
    
    log = execute_plan(steps, csv, log, on_step=_on_cli,
                      progress_manager=cli_progress.progress_manager,
                      phase_name="EDAåˆæœŸåˆ†æ")

    # 2) åçœâ†’å†è¨ˆç”»ã‚’æœ€å¤§2å›
    for i in range(2):
        if has_llm:
            assert llm is not None
            cli_progress.start_phase(f"EDAæ”¹å–„ ãƒ©ã‚¦ãƒ³ãƒ‰{i+1}", message=f"åˆ†æçµæœã‚’æ”¹å–„ã—ã¾ã™ï¼ˆ{i+1}/2ï¼‰")
            steps = next_eda_plan(llm, log)
            total = max(1, len(steps))
            phase_idx += 1
            log = execute_plan(steps, csv, log, on_step=_on_cli,
                              progress_manager=cli_progress.progress_manager,
                              phase_name=f"EDAæ”¹å–„ ãƒ©ã‚¦ãƒ³ãƒ‰{i+1}")
            if any(s.action=="stop" for s in steps):
                break
        else:
            break
    
    cli_progress.complete_phase("EDAåˆ†æå®Œäº†")

    # 3) ãƒ¬ãƒãƒ¼ãƒˆåŒ–
    path = render_eda(csv)
    print(json.dumps({"report_md": path, "turns": len(log.turns)}, ensure_ascii=False))
    # 4) ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆCLIï¼‰
    cli_progress.start_phase("ãƒ¢ãƒ‡ãƒªãƒ³ã‚°", message="æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’é–‹å§‹")
    
    import pandas as pd  # type: ignore[reportMissingImports]
    df = pd.read_csv(csv)
    task, ycol = infer_task_and_target(df, hint=os.getenv("TARGET"))
    
    def _model_progress(stage: str, frac: float):
        cli_progress.update_step(stage, f"é€²æ—: {int(frac*100)}%")
    
    result = train_candidates(df, task, ycol, progress=_model_progress)
    print("Modeling:", json.dumps(result, ensure_ascii=False))
    
    if has_llm:
        try:
            from src.agents.model_agent import reflect_and_improve
            from src.runners.code_runner import run_python
            
            for i in range(2):
                cli_progress.start_phase(f"ãƒ¢ãƒ‡ãƒ«æ”¹å–„ ãƒ©ã‚¦ãƒ³ãƒ‰{i+1}", message=f"ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ”¹å–„ã‚’å®Ÿè¡Œï¼ˆ{i+1}/2ï¼‰")
                steps2 = reflect_and_improve(llm, json.dumps(result, ensure_ascii=False))
                if not steps2:
                    break
                
                for j, s in enumerate(steps2):
                    if s.get("action")=="python":
                        cli_progress.update_step(f"æ”¹å–„ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ {j+1}/{len(steps2)}")
                        run_python(s.get("code",""), input_csv=csv)
                
                df = pd.read_csv(csv)
                result = train_candidates(df, task, ycol, progress=_model_progress)
        except Exception as e:
            cli_progress.error_phase(f"ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    cli_progress.complete_phase("å…¨å‡¦ç†å®Œäº†")
    open("data/artifacts/model_scores.json","w",encoding="utf-8").write(json.dumps(result, ensure_ascii=False, indent=2))
    
    # æœ€çµ‚çš„ãªé€²æ—ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
    print("\n" + "="*60)
    print("ğŸ‰ å‡¦ç†å®Œäº†ã‚µãƒãƒªãƒ¼")
    print("="*60)
    from src.utils.dashboard import print_dashboard_summary
    print_dashboard_summary(cli_progress.progress_manager)
