# src/utils/checkpoint.py
"""ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  - ä¸­é–“çŠ¶æ…‹ä¿å­˜ãƒ»å¾©å…ƒæ©Ÿèƒ½"""

from __future__ import annotations
import json
import pickle
import os
import shutil
import sys
import time
from typing import Dict, Any, Optional, List, Union, Callable
from pathlib import Path
from datetime import datetime, timezone
from dataclasses import dataclass, asdict
import hashlib

from .progress import ProgressState, ProgressManager


@dataclass
class CheckpointMetadata:
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
    checkpoint_id: str
    timestamp: str
    phase: str
    step_count: int
    progress: float
    description: str
    file_size_bytes: int
    artifacts_count: int
    hash_md5: str


class CheckpointManager:
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, checkpoint_dir: str = "data/checkpoints"):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        self.metadata_file = self.checkpoint_dir / "checkpoints.json"
        self.auto_save_enabled = True
        self.auto_save_interval = 300  # 5åˆ†é–“éš”
        self.max_checkpoints = 10  # æœ€å¤§ä¿æŒæ•°
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.checkpoints_metadata: Dict[str, CheckpointMetadata] = {}
        self._load_metadata()
        
        self.last_auto_save = 0.0
    
    def _load_metadata(self):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if self.metadata_file.exists():
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                for checkpoint_id, metadata_dict in data.items():
                    self.checkpoints_metadata[checkpoint_id] = CheckpointMetadata(**metadata_dict)
        except Exception as e:
            print(f"âš ï¸ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
    
    def _save_metadata(self):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        try:
            data = {}
            for checkpoint_id, metadata in self.checkpoints_metadata.items():
                data[checkpoint_id] = asdict(metadata)
            
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¤±æ•—: {e}")
    
    def _generate_checkpoint_id(self, phase: str) -> str:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆIDã‚’ç”Ÿæˆ"""
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        phase_short = phase.replace(" ", "_").replace("-", "_")[:20]
        return f"{timestamp}_{phase_short}"
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®MD5ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception:
            return ""
    
    def create_checkpoint(self, 
                         progress_manager: ProgressManager, 
                         description: str = "",
                         include_artifacts: bool = True,
                         force: bool = False) -> str:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½œæˆ"""
        if not force and not self._should_create_checkpoint():
            return ""
        
        try:
            state = progress_manager.state
            checkpoint_id = self._generate_checkpoint_id(state.phase)
            checkpoint_path = self.checkpoint_dir / checkpoint_id
            checkpoint_path.mkdir(exist_ok=True)
            
            # é€²æ—çŠ¶æ…‹ã‚’ä¿å­˜
            progress_data = {
                "current_state": asdict(state),
                "phase_history": [asdict(h) for h in progress_manager.phase_history],
                "overall_progress": progress_manager.get_overall_progress()
            }
            
            progress_file = checkpoint_path / "progress.json"
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
            
            # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ã‚³ãƒ”ãƒ¼
            artifacts_count = 0
            if include_artifacts:
                artifacts_count = self._backup_artifacts(checkpoint_path)
            
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’ä¿å­˜
            system_data = {
                "python_version": sys.version,
                "working_directory": str(Path.cwd()),
                "environment_variables": {
                    k: v for k, v in os.environ.items() 
                    if k.startswith(('LLM_', 'OPENAI_', 'ANTHROPIC_', 'FAST_', 'USE_'))
                },
                "checkpoint_time": datetime.now(timezone.utc).isoformat()
            }
            
            system_file = checkpoint_path / "system.json"
            with open(system_file, 'w', encoding='utf-8') as f:
                json.dump(system_data, f, ensure_ascii=False, indent=2)
            
            # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå…¨ä½“ã®ã‚µã‚¤ã‚ºã¨ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—
            total_size = sum(f.stat().st_size for f in checkpoint_path.rglob('*') if f.is_file())
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            metadata = CheckpointMetadata(
                checkpoint_id=checkpoint_id,
                timestamp=datetime.now(timezone.utc).isoformat(),
                phase=state.phase,
                step_count=state.current_step,
                progress=state.progress,
                description=description or f"è‡ªå‹•ä¿å­˜: {state.phase}",
                file_size_bytes=total_size,
                artifacts_count=artifacts_count,
                hash_md5=self._calculate_file_hash(progress_file)
            )
            
            self.checkpoints_metadata[checkpoint_id] = metadata
            self._save_metadata()
            
            # å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤
            self._cleanup_old_checkpoints()
            
            self.last_auto_save = time.time()
            
            print(f"ğŸ’¾ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆå®Œäº†: {checkpoint_id}")
            print(f"   ğŸ“ ã‚µã‚¤ã‚º: {total_size / 1024:.1f}KB, ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ: {artifacts_count}å€‹")
            
            return checkpoint_id
        
        except Exception as e:
            print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆå¤±æ•—: {e}")
            return ""
    
    def _backup_artifacts(self, checkpoint_path: Path) -> int:
        """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        artifacts_dir = Path("data/artifacts")
        if not artifacts_dir.exists():
            return 0
        
        backup_dir = checkpoint_path / "artifacts"
        backup_dir.mkdir(exist_ok=True)
        
        count = 0
        try:
            for artifact_file in artifacts_dir.glob("*"):
                if artifact_file.is_file():
                    shutil.copy2(artifact_file, backup_dir / artifact_file.name)
                    count += 1
        except Exception as e:
            print(f"âš ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã§ä¸€éƒ¨å¤±æ•—: {e}")
        
        return count
    
    def _should_create_checkpoint(self) -> bool:
        """è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆã®åˆ¤å®š"""
        if not self.auto_save_enabled:
            return False
        
        return (time.time() - self.last_auto_save) >= self.auto_save_interval
    
    def restore_checkpoint(self, checkpoint_id: str) -> Optional[ProgressManager]:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å¾©å…ƒ"""
        try:
            if checkpoint_id not in self.checkpoints_metadata:
                print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {checkpoint_id}")
                return None
            
            checkpoint_path = self.checkpoint_dir / checkpoint_id
            if not checkpoint_path.exists():
                print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {checkpoint_path}")
                return None
            
            # é€²æ—çŠ¶æ…‹ã‚’å¾©å…ƒ
            progress_file = checkpoint_path / "progress.json"
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            # ProgressManagerã‚’å†æ§‹ç¯‰
            progress_manager = ProgressManager()
            
            # ç¾åœ¨ã®çŠ¶æ…‹ã‚’å¾©å…ƒ
            current_state_dict = progress_data["current_state"]
            progress_manager.state = ProgressState(**current_state_dict)
            
            # ãƒ•ã‚§ãƒ¼ã‚ºå±¥æ­´ã‚’å¾©å…ƒ
            progress_manager.phase_history = [
                ProgressState(**hist) for hist in progress_data["phase_history"]
            ]
            
            # ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’å¾©å…ƒ
            self._restore_artifacts(checkpoint_path)
            
            print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒå®Œäº†: {checkpoint_id}")
            print(f"   ğŸ“Š ãƒ•ã‚§ãƒ¼ã‚º: {progress_manager.state.phase}")
            print(f"   ğŸ“ˆ é€²æ—: {int(progress_manager.state.progress * 100)}%")
            
            return progress_manager
        
        except Exception as e:
            print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå¾©å…ƒå¤±æ•—: {e}")
            return None
    
    def _restore_artifacts(self, checkpoint_path: Path):
        """ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’å¾©å…ƒ"""
        backup_dir = checkpoint_path / "artifacts"
        if not backup_dir.exists():
            return
        
        artifacts_dir = Path("data/artifacts")
        artifacts_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            for backup_file in backup_dir.glob("*"):
                if backup_file.is_file():
                    shutil.copy2(backup_file, artifacts_dir / backup_file.name)
            
            print(f"   ğŸ“ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå¾©å…ƒå®Œäº†")
        except Exception as e:
            print(f"âš ï¸ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆå¾©å…ƒã§ä¸€éƒ¨å¤±æ•—: {e}")
    
    def list_checkpoints(self) -> List[CheckpointMetadata]:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—"""
        return sorted(
            self.checkpoints_metadata.values(),
            key=lambda x: x.timestamp,
            reverse=True
        )
    
    def delete_checkpoint(self, checkpoint_id: str) -> bool:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤"""
        try:
            if checkpoint_id not in self.checkpoints_metadata:
                print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {checkpoint_id}")
                return False
            
            checkpoint_path = self.checkpoint_dir / checkpoint_id
            if checkpoint_path.exists():
                shutil.rmtree(checkpoint_path)
            
            del self.checkpoints_metadata[checkpoint_id]
            self._save_metadata()
            
            print(f"ğŸ—‘ï¸ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤å®Œäº†: {checkpoint_id}")
            return True
        
        except Exception as e:
            print(f"âŒ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå‰Šé™¤å¤±æ•—: {e}")
            return False
    
    def _cleanup_old_checkpoints(self):
        """å¤ã„ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        checkpoints = self.list_checkpoints()
        
        if len(checkpoints) > self.max_checkpoints:
            # å¤ã„ã‚‚ã®ã‹ã‚‰å‰Šé™¤
            for checkpoint in checkpoints[self.max_checkpoints:]:
                self.delete_checkpoint(checkpoint.checkpoint_id)
    
    def get_checkpoint_size(self) -> Dict[str, Any]:
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆå…¨ä½“ã®ã‚µã‚¤ã‚ºæƒ…å ±ã‚’å–å¾—"""
        total_size = 0
        checkpoint_count = len(self.checkpoints_metadata)
        
        try:
            for checkpoint_path in self.checkpoint_dir.iterdir():
                if checkpoint_path.is_dir():
                    total_size += sum(f.stat().st_size for f in checkpoint_path.rglob('*') if f.is_file())
        except Exception:
            pass
        
        return {
            "total_size_bytes": total_size,
            "total_size_mb": total_size / (1024 * 1024),
            "checkpoint_count": checkpoint_count,
            "max_checkpoints": self.max_checkpoints,
            "auto_save_enabled": self.auto_save_enabled,
            "auto_save_interval": self.auto_save_interval
        }


def create_checkpoint_callback(checkpoint_manager: CheckpointManager) -> Callable:
    """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆ"""
    def checkpoint_callback(state: ProgressState):
        # ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†æ™‚ã«è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä½œæˆ
        if state.status == "completed":
            checkpoint_manager.create_checkpoint(
                progress_manager=None,  # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ã§ã¯ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãŸã‚
                description=f"ãƒ•ã‚§ãƒ¼ã‚ºå®Œäº†: {state.phase}",
                force=True
            )
    
    return checkpoint_callback


def setup_auto_checkpoint(progress_manager: ProgressManager, 
                         interval_minutes: int = 5,
                         max_checkpoints: int = 10) -> CheckpointManager:
    """è‡ªå‹•ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆè¨­å®š"""
    checkpoint_manager = CheckpointManager()
    checkpoint_manager.auto_save_enabled = True
    checkpoint_manager.auto_save_interval = interval_minutes * 60
    checkpoint_manager.max_checkpoints = max_checkpoints
    
    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™»éŒ²
    callback = create_checkpoint_callback(checkpoint_manager)
    progress_manager.add_callback(callback)
    
    return checkpoint_manager
